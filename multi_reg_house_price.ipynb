{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy,math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Volumes/DevT7/vscode/projects/Pythonvscode/Machine Learning/Data/house_price_train.csv\")\n",
    "test=pd.read_csv(\"/Volumes/DevT7/vscode/projects/Pythonvscode/Machine Learning/Data/house_price_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>14115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>10084</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.634603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>10382</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.206073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>6120</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11.774520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>3</td>\n",
       "      <td>7420</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11.678440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  MSSubClass  MSZoning  LotArea  Street  LotShape  \\\n",
       "0           0   1          60         3     8450       1         3   \n",
       "1           1   2          20         3     9600       1         3   \n",
       "2           2   3          60         3    11250       1         0   \n",
       "3           3   4          70         3     9550       1         0   \n",
       "4           4   5          60         3    14260       1         0   \n",
       "5           5   6          50         3    14115       1         0   \n",
       "6           6   7          20         3    10084       1         3   \n",
       "7           7   8          60         3    10382       1         0   \n",
       "8           8   9          50         4     6120       1         3   \n",
       "9           9  10         190         3     7420       1         3   \n",
       "\n",
       "   LandContour  Utilities  LotConfig  ...  EnclosedPorch  3SsnPorch  \\\n",
       "0            3          0          4  ...              0          0   \n",
       "1            3          0          2  ...              0          0   \n",
       "2            3          0          4  ...              0          0   \n",
       "3            3          0          0  ...            272          0   \n",
       "4            3          0          2  ...              0          0   \n",
       "5            3          0          4  ...              0        320   \n",
       "6            3          0          4  ...              0          0   \n",
       "7            3          0          0  ...            228          0   \n",
       "8            3          0          4  ...            205          0   \n",
       "9            3          0          0  ...              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \\\n",
       "0            0         0        0       2    2008         8              4   \n",
       "1            0         0        0       5    2007         8              4   \n",
       "2            0         0        0       9    2008         8              4   \n",
       "3            0         0        0       2    2006         8              0   \n",
       "4            0         0        0      12    2008         8              4   \n",
       "5            0         0      700      10    2009         8              4   \n",
       "6            0         0        0       8    2007         8              4   \n",
       "7            0         0      350      11    2009         8              4   \n",
       "8            0         0        0       4    2008         8              0   \n",
       "9            0         0        0       1    2008         8              4   \n",
       "\n",
       "   SalePrice  \n",
       "0  12.247694  \n",
       "1  12.109011  \n",
       "2  12.317167  \n",
       "3  11.849398  \n",
       "4  12.429216  \n",
       "5  11.870600  \n",
       "6  12.634603  \n",
       "7  12.206073  \n",
       "8  11.774520  \n",
       "9  11.678440  \n",
       "\n",
       "[10 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unwanted data from dataset\n",
    "train = train.drop([\"Unnamed: 0\", \"Id\"], axis = 1)\n",
    "test = test.drop([\"Unnamed: 0\", \"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating target and training values\n",
    "train_data = train.values\n",
    "Y = train_data[:, -1].reshape(train_data.shape[0], 1)\n",
    "X = train_data[:, :-1]\n",
    "\n",
    "test_data = test.values\n",
    "Y_test = test_data[:, -1].reshape(test_data.shape[0], 1)\n",
    "X_test = test_data[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (1200, 69)\n",
      "Shape of Y_train : (1200, 1)\n",
      "Shape of X_test : (258, 69)\n",
      "Shape of Y_test : (258, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train :\", X.shape)\n",
    "print(\"Shape of Y_train :\", Y.shape)\n",
    "print(\"Shape of X_test :\", X_test.shape)\n",
    "print(\"Shape of Y_test :\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X)\n",
    "y_train=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (1200, 69), X Type:<class 'numpy.ndarray'>)\n",
      "[[6.0000e+01 3.0000e+00 8.4500e+03 ... 2.0080e+03 8.0000e+00 4.0000e+00]\n",
      " [2.0000e+01 3.0000e+00 9.6000e+03 ... 2.0070e+03 8.0000e+00 4.0000e+00]\n",
      " [6.0000e+01 3.0000e+00 1.1250e+04 ... 2.0080e+03 8.0000e+00 4.0000e+00]\n",
      " ...\n",
      " [2.0000e+01 3.0000e+00 9.1000e+03 ... 2.0090e+03 8.0000e+00 4.0000e+00]\n",
      " [2.0000e+01 3.0000e+00 1.1235e+04 ... 2.0060e+03 8.0000e+00 4.0000e+00]\n",
      " [2.0000e+01 3.0000e+00 9.3530e+03 ... 2.0060e+03 7.0000e+00 0.0000e+00]]\n",
      "y Shape: (1200, 1), y Type:<class 'numpy.ndarray'>)\n",
      "[[12.24769432]\n",
      " [12.10901093]\n",
      " [12.31716669]\n",
      " ...\n",
      " [12.08953883]\n",
      " [11.90496755]\n",
      " [11.66177641]]\n"
     ]
    }
   ],
   "source": [
    "# data is stored in numpy array/matrix\n",
    "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (69,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "values_array = np.random.uniform(0, 100, size=69)\n",
    "\n",
    "b_init = 785.1811367994083\n",
    "w_init = np.array(values_array)\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_loop(x,w,b):\n",
    "    n=x.shape[0]\n",
    "    p=0\n",
    "    for i in range(n):\n",
    "        p_i=x[i]*w[i]\n",
    "        p=p+p_i\n",
    "    p=p+b\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (69,), x_vec value: [6.000e+01 3.000e+00 8.450e+03 1.000e+00 3.000e+00 3.000e+00 0.000e+00\n",
      " 4.000e+00 0.000e+00 5.000e+00 2.000e+00 2.000e+00 0.000e+00 5.000e+00\n",
      " 7.000e+00 5.000e+00 2.003e+03 2.003e+03 1.000e+00 0.000e+00 1.200e+01\n",
      " 1.300e+01 1.000e+00 1.960e+02 2.000e+00 4.000e+00 2.000e+00 2.000e+00\n",
      " 3.000e+00 3.000e+00 2.000e+00 7.060e+02 5.000e+00 0.000e+00 1.500e+02\n",
      " 8.560e+02 1.000e+00 0.000e+00 1.000e+00 4.000e+00 8.540e+02 0.000e+00\n",
      " 1.710e+03 1.000e+00 0.000e+00 2.000e+00 1.000e+00 3.000e+00 1.000e+00\n",
      " 2.000e+00 6.000e+00 0.000e+00 1.000e+00 1.000e+00 2.000e+00 4.000e+00\n",
      " 4.000e+00 2.000e+00 0.000e+00 6.100e+01 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 2.000e+00 2.008e+03 8.000e+00 4.000e+00]\n",
      "f_wb shape (), prediction: 859205.4051554501\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (69,), x_vec value: [6.000e+01 3.000e+00 8.450e+03 1.000e+00 3.000e+00 3.000e+00 0.000e+00\n",
      " 4.000e+00 0.000e+00 5.000e+00 2.000e+00 2.000e+00 0.000e+00 5.000e+00\n",
      " 7.000e+00 5.000e+00 2.003e+03 2.003e+03 1.000e+00 0.000e+00 1.200e+01\n",
      " 1.300e+01 1.000e+00 1.960e+02 2.000e+00 4.000e+00 2.000e+00 2.000e+00\n",
      " 3.000e+00 3.000e+00 2.000e+00 7.060e+02 5.000e+00 0.000e+00 1.500e+02\n",
      " 8.560e+02 1.000e+00 0.000e+00 1.000e+00 4.000e+00 8.540e+02 0.000e+00\n",
      " 1.710e+03 1.000e+00 0.000e+00 2.000e+00 1.000e+00 3.000e+00 1.000e+00\n",
      " 2.000e+00 6.000e+00 0.000e+00 1.000e+00 1.000e+00 2.000e+00 4.000e+00\n",
      " 4.000e+00 2.000e+00 0.000e+00 6.100e+01 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 2.000e+00 2.008e+03 8.000e+00 4.000e+00]\n",
      "f_wb shape (), prediction: 859205.4051554501\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters\n",
    "      b (scalar):             model parameter\n",
    "\n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (69,), x_vec value: [6.000e+01 3.000e+00 8.450e+03 1.000e+00 3.000e+00 3.000e+00 0.000e+00\n",
      " 4.000e+00 0.000e+00 5.000e+00 2.000e+00 2.000e+00 0.000e+00 5.000e+00\n",
      " 7.000e+00 5.000e+00 2.003e+03 2.003e+03 1.000e+00 0.000e+00 1.200e+01\n",
      " 1.300e+01 1.000e+00 1.960e+02 2.000e+00 4.000e+00 2.000e+00 2.000e+00\n",
      " 3.000e+00 3.000e+00 2.000e+00 7.060e+02 5.000e+00 0.000e+00 1.500e+02\n",
      " 8.560e+02 1.000e+00 0.000e+00 1.000e+00 4.000e+00 8.540e+02 0.000e+00\n",
      " 1.710e+03 1.000e+00 0.000e+00 2.000e+00 1.000e+00 3.000e+00 1.000e+00\n",
      " 2.000e+00 6.000e+00 0.000e+00 1.000e+00 1.000e+00 2.000e+00 4.000e+00\n",
      " 4.000e+00 2.000e+00 0.000e+00 6.100e+01 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 2.000e+00 2.008e+03 8.000e+00 4.000e+00]\n",
      "f_wb shape (), prediction: 859205.4051554501\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters\n",
    "      b (scalar)       : model parameter\n",
    "\n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : [5.34697635e+11]\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters.\n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters\n",
    "      b (scalar)       : model parameter\n",
    "\n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w.\n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b.\n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):\n",
    "        err = (np.dot(X[i], w) + b) - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
    "        dj_db = dj_db + err\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "\n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking\n",
    "    num_iters gradient steps with learning rate alpha\n",
    "\n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters\n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "\n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters\n",
    "      b (scalar)       : Updated value of parameter\n",
    "      \"\"\"\n",
    "\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion\n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters /10) == 0:\n",
    "          pass\n",
    "            #print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "\n",
    "    return w, b,J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/vtxh24v91hxg3qfhstmc8d0c0000gn/T/ipykernel_47888/1291870043.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
      "/var/folders/fp/vtxh24v91hxg3qfhstmc8d0c0000gn/T/ipykernel_47888/2373855227.py:17: RuntimeWarning: overflow encountered in add\n",
      "  cost = cost + (f_wb_i - y[i])**2       #scalar\n",
      "/var/folders/fp/vtxh24v91hxg3qfhstmc8d0c0000gn/T/ipykernel_47888/2373855227.py:17: RuntimeWarning: overflow encountered in square\n",
      "  cost = cost + (f_wb_i - y[i])**2       #scalar\n",
      "/var/folders/fp/vtxh24v91hxg3qfhstmc8d0c0000gn/T/ipykernel_47888/1291870043.py:21: RuntimeWarning: overflow encountered in add\n",
      "  dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
      "/var/folders/fp/vtxh24v91hxg3qfhstmc8d0c0000gn/T/ipykernel_47888/1291870043.py:21: RuntimeWarning: invalid value encountered in multiply\n",
      "  dj_dw[j] = dj_dw[j] + err * X[i, j]\n",
      "/var/folders/fp/vtxh24v91hxg3qfhstmc8d0c0000gn/T/ipykernel_47888/3045136546.py:32: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w - alpha * dj_dw               ##None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# run gradient descent\u001b[39;00m\n\u001b[1;32m      8\u001b[0m w_final, b_final, J_hist \u001b[38;5;241m=\u001b[39m gradient_descent(X_train, y_train, initial_w, initial_b,\n\u001b[1;32m      9\u001b[0m                                                     compute_cost, compute_gradient,\n\u001b[1;32m     10\u001b[0m                                                     alpha, iterations)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,w found by gradient descent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_final\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw_final\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m m,_ \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient,\n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
